<!DOCTYPE html>
<html>

<head>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="style.css">
	<title>aradhye agarwal</title>
</head>

<body>
	<img id="profile_pic" src="assets/profile_pic.png" alt="aradhye agarwal">

	<h1>aradhye agarwal</h1>

	<h3>
	<a href="assets/resume.pdf">resume</a>
	| <a href="https://scholar.google.com/citations?user=EPCLlPMAAAAJ&hl=en">scholar</a>
	| <a href="https://github.com/Aradhye2002">github</a>
	| <a href="mailto:aradhyeagarwal@gmail.com">email</a>
	</h3>

	<br>

	<p>
	I am a final-year Dual Degree (UG) student in Computer Science and Engineering at the Indian Institute of Technology, Delhi. I am a part of the <a href="https://www.lcs2.in/">LCS2 lab</a>, under Prof. <a href="https://tanmoychak.com/">Tanmoy Chakraborty</a>, where we work on
	reducing the computational costs associated with LLM finetuning and inference. Earlier, I had the opportunity to work with Prof. <a href="https://www.cse.iitd.ac.in/~chetan/">Chetan Arora</a>, with whom I published my very first paper in CVPR'24 which was on monocular depth estimation. Before this,
	I worked with Prof. <a href="https://www.cse.iitd.ac.in/~rohanpaul/">Rohan Paul</a> on robust verbal communication with field robots through the use of contextual correction of transcriptions.
	</p>

	<h2>news</h2>

	<table>

	<tr>
		<th>Nov 12, 2024</th>
		<td>This webpage is live.</td>
	</tr>

	</table>

	<h2>publications</h2>

	(* denotes equal contribution)

	<ol>

	<li>
		<b>ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation</b><br>
		Suraj Patni*, <u>Aradhye Agarwal*</u>, Chetan Arora<br>
		<i>Computer Vision and Pattern Recognition (CVPR), 2024</i><br>

		<a href="assets/2024/ecodepth/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2403.18807">arxiv</a>
		| <a href="https://github.com/Aradhye2002/EcoDepth">code</a>
		| <a href="https://ecodepth-iitd.github.io/">website</a>
		| <a href="assets/2024/ecodepth/cite.txt">cite</a>
	</li>

	<li>
		<b>The Third Monocular Depth Estimation Challenge</b><br>
		<i>Computer Vision and Pattern Recognition Workshop (CVPRW), 2024</i><br>

		<a href="assets/2024/mdec/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2404.16831">arxiv</a>
		| <a href="https://jspenmar.github.io/MDEC/">website</a>
		| <a href="assets/2024/mdec/cite.txt">cite</a>
	</li>

	<li>
		<b>Step-by-Step Unmasking for Parameter-Efficient Fine-tuning of Large Language Models</b><br>
		<u>Aradhye Agarwal*</u>, Suhas Kamasetty Ramesh*, Ayan Sengupta*, Tanmoy Chakraborty<br>
		<i>Under review</i><br>

		<a href="assets/2024/id3/paper.pdf">paper</a>
		| <a href="https://arxiv.org/abs/2408.14470">arxiv</a>
		| <a href="https://github.com/Aradhye2002/selective-peft-toolkit">code</a>
		| <a href="assets/2024/id3/cite.txt">cite</a>
	</li>
	</ol>

	<footer>
		Made with &#10084;&#65039; in plain HTML and CSS (<a href="https://github.com/Aradhye2002/aradhye-agarwal.github.io">code</a>).
	<footer>
</body>

</html>
